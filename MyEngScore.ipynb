{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07691643",
      "metadata": {
        "id": "07691643"
      },
      "source": [
        "<div style=\"padding:20px 30px 30px; \n",
        "            color:#004346;\n",
        "            font-size:40px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "<p style=\"font-weight: bold; text-align: center;\">Определение уровня сложности фильмов</p>\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbb2e47d",
      "metadata": {
        "id": "fbb2e47d"
      },
      "source": [
        "<div style=\"padding:0px 40px 30px; \n",
        "            color:#004346;\n",
        "            font-size:110%;\n",
        "            display:fill;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:450;\"> \n",
        "    \n",
        "__Постановка проблемы:__ Просмотр фильмов на оригинальном языке - это популярный и действенный метод прокачаться при изучении иностранных языков. Важно выбрать фильм, который подходит студенту по уровню сложности, т.е. студент понимал 50-70 % диалогов. Чтобы выполнить это условие, преподаватель должен посмотреть фильм и решить, какому уровню он соответствует. Однако это требует больших временных затрат.\n",
        "    \n",
        "__Цель:__ Разработать ML решение для автоматического определения уровня сложности англоязычных фильмов, разработать для неё веб-интерфейс и создать микросервис. \n",
        "    \n",
        "__Описание данных:__\n",
        "\n",
        "- субтитры фильмов, сохраненные в директориях, названия которых, соответствуют уровню сложности по шкале CEFR([Common European Framework of Reference]('https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%89%D0%B5%D0%B5%D0%B2%D1%80%D0%BE%D0%BF%D0%B5%D0%B9%D1%81%D0%BA%D0%B8%D0%B5_%D0%BA%D0%BE%D0%BC%D0%BF%D0%B5%D1%82%D0%B5%D0%BD%D1%86%D0%B8%D0%B8_%D0%B2%D0%BB%D0%B0%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F_%D0%B8%D0%BD%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%BD%D1%8B%D0%BC_%D1%8F%D0%B7%D1%8B%D0%BA%D0%BE%D0%BC' 'wikipedia'))\n",
        "    \n",
        "- субтитры фильмов и [фaйл xlsx](https://i.postimg.cc/8zXN4BJ6/2023-06-08-11-58-46.png), содержаший название фильмов и уровню сложности по шкале CEFR\n",
        "    \n",
        "- список слов, по уровлю сложности Oxford level.\n",
        "</div>        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cf617c",
      "metadata": {
        "id": "c7cf617c"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "# Используемые библиотеки\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "338ab3d4",
      "metadata": {
        "scrolled": true,
        "id": "338ab3d4",
        "outputId": "6eb0843c-34df-4cd4-ae72-6c0210a528d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/denismuhanov/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/denismuhanov/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/denismuhanov/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pysrt\n",
        "import re\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import joblib\n",
        "import random\n",
        "import optuna\n",
        "import warnings\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, mean_absolute_error\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from catboost import Pool, CatBoostRegressor\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "# константы\n",
        "RANDOM_SEED = 42\n",
        "EARLY_STOPPING_ROUND = 100\n",
        "\n",
        "HTML = r'<.*?>'\n",
        "TAG = r'{.*?}'\n",
        "COMMENTS = r'[\\(\\[][A-Z ]+[\\)\\]]'\n",
        "LETTERS = r'[^a-zA-Z\\'.,!? ]'\n",
        "SPACES = r'([ ])\\1+'\n",
        "DOTS = r'[\\.]+'\n",
        "PUNCTUATION = re.compile('[^а-яa-z\\s]')\n",
        "\n",
        "# настройки блокнота\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.options.display.max_colwidth = None\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48897f1b",
      "metadata": {
        "id": "48897f1b"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "# Загрузка и первичная обработка данных\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cca8838",
      "metadata": {
        "id": "5cca8838",
        "outputId": "6852da61-28e0-4204-df8b-c10e026c5274"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Данные загруженны коректно'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "try:\n",
        "    # путь к папке с файлами субтитров\n",
        "    subtitles_folder = Path('data/subtitles/subtitles_cerf/')\n",
        "    subtitles_folder2 = 'data/subtitles/subtitles_no_labels'\n",
        "    excel_file = 'data/subtitles/movies_labels.xlsx'\n",
        "\n",
        "    # загрузка данных для рассчета статистической информации:\n",
        "    a1_list = next(csv.reader(open('data/a1.csv', 'r')))\n",
        "    a2_list = next(csv.reader(open('data/a2.csv', 'r')))\n",
        "    b1_list = next(csv.reader(open('data/b1.csv', 'r')))\n",
        "    b2_list = next(csv.reader(open('data/b2.csv', 'r')))\n",
        "    c1_list = next(csv.reader(open('data/c1.csv', 'r')))\n",
        "    display('Данные загруженны коректно')\n",
        "except:\n",
        "    display('Данные не доступны')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "035c05e0",
      "metadata": {
        "id": "035c05e0"
      },
      "outputs": [],
      "source": [
        "# функция для первичной обработки текста\n",
        "def clean_subs(txt):\n",
        "    txt = re.sub(HTML, ' ', txt) #html тэги меняем на пробел\n",
        "    txt = re.sub(TAG, ' ', txt) #тэги меняем на пробел\n",
        "    txt = re.sub(COMMENTS, ' ', txt) #комменты меняем на пробел\n",
        "    txt = re.sub(LETTERS, ' ', txt) #все что не буквы меняем на пробел\n",
        "    txt = re.sub(SPACES, r'\\1', txt) #повторяющиеся пробелы меняем на один пробел\n",
        "    txt = re.sub(DOTS, r'.', txt) #многоточие меняем на точку\n",
        "    txt = txt.encode('ascii', 'ignore').decode() #удаляем все что не ascii символы\n",
        "    txt = \".\".join(txt.lower().split('.')[1:-1]) #удаляем первый и последний субтитр (обычно это реклама)\n",
        "    txt = txt.replace('. .', '. ')\n",
        "    return txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30e616b2",
      "metadata": {
        "id": "30e616b2"
      },
      "source": [
        "__Получение первой части размеченных данных__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a83f42ac",
      "metadata": {
        "id": "a83f42ac"
      },
      "outputs": [],
      "source": [
        "# получение списока файлов субтитров в папке\n",
        "subtitles_files = subtitles_folder.rglob('*.srt')\n",
        "# cоздание пустого датафрейма для хранения данных\n",
        "df = pd.DataFrame(columns=['movie', 'subtitles', 'label'])\n",
        "# загрузка и первичня обработка субтитров\n",
        "data = []\n",
        "for file_path in subtitles_files:\n",
        "    subs = pysrt.open(str(file_path), encoding='latin-1')\n",
        "    if len(subs) == 0:\n",
        "        subs = pysrt.open(str(file_path), encoding='utf-16') #учитываем альтернативную кодировку\n",
        "    txt = ' '.join([sub.text for sub in subs])\n",
        "    subtitle_text = clean_subs(txt)\n",
        "    data.append({'movie': file_path.name[:-4], 'subtitles': subtitle_text, 'label': file_path.parent.name})\n",
        "    \n",
        "# объединяем все записи в датасете с помощью функции concat\n",
        "df = pd.concat([df, pd.DataFrame(data)], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9467220c",
      "metadata": {
        "id": "9467220c"
      },
      "source": [
        "__Получение второй части размеченных данных__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "528a3c57",
      "metadata": {
        "id": "528a3c57"
      },
      "outputs": [],
      "source": [
        "# загрузка датафрейма из файла excel\n",
        "df2 = pd.read_excel(excel_file)\n",
        "# удаление столбца, не использующего в дальнейшем анализе: `id`\n",
        "df2 = df2.drop('id', axis=1)\n",
        "# переименование признаков для последующей конкатинации датасетов\n",
        "df2.rename(columns = {\n",
        "    'Movie':'movie',\n",
        "    'Level':'label'\n",
        "    }, inplace = True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa4d4282",
      "metadata": {
        "id": "aa4d4282"
      },
      "outputs": [],
      "source": [
        "# функция для добавления судтитров, по названию фильмов и первичной обработки\n",
        "def add_srt(x):\n",
        "    try:\n",
        "        file_path = subtitles_folder2+x+'.srt'\n",
        "        subs = pysrt.open(file_path, encoding='latin-1')\n",
        "        if len(subs) == 0:\n",
        "            subs = pysrt.open(str(file_path), encoding='utf-16') #учитываем альтернативную кодировку\n",
        "        txt = ' '.join([sub.text for sub in subs])\n",
        "        clean_text = clean_subs(txt)\n",
        "        return clean_text\n",
        "    except FileNotFoundError:\n",
        "        return np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bab0cc80",
      "metadata": {
        "id": "bab0cc80"
      },
      "outputs": [],
      "source": [
        "# добавление судтитров\n",
        "df2['subtitles'] = df2['movie'].apply(add_srt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb94408d",
      "metadata": {
        "id": "cb94408d"
      },
      "source": [
        "__Объединие данных__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25f8e00a",
      "metadata": {
        "id": "25f8e00a"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df, df2], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab94a274",
      "metadata": {
        "id": "ab94a274"
      },
      "source": [
        "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
        "\n",
        "\n",
        "- Субтитры загружены и объединены в датасет\n",
        "- Проведена первичная обработка субтитров:\n",
        "    - html тэги заменены на пробел\n",
        "    - комментарии заменены на пробел\n",
        "    - все что не является буквами заменены на пробел\n",
        "    - повторяющиеся пробелы заменены на один пробел\n",
        "    - многоточия заменены на точку\n",
        "    - удалены все что не ascii символы\n",
        "    - удалены первый и последний субтитр (обычно это реклама)\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad7865ff",
      "metadata": {
        "id": "ad7865ff"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "# Предобработка и исследовательский анализ данных\n",
        "\n",
        "## Общая информация\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d001a72",
      "metadata": {
        "id": "8d001a72",
        "outputId": "a3391b9f-e689-40b3-98f8-4da922cf854d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 404 entries, 0 to 403\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   movie      404 non-null    object\n",
            " 1   subtitles  273 non-null    object\n",
            " 2   label      404 non-null    object\n",
            "dtypes: object(3)\n",
            "memory usage: 9.6+ KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0c0b887",
      "metadata": {
        "id": "a0c0b887"
      },
      "source": [
        "- Названия фильмов не несут информацию и сложности диалогов в нем, поэтому: данный признак можно удалить.\n",
        "- В данных присутствуют пропуски, это связано с тем, что в файле excel, были перечислеыы часть фильмов, распрелеленных по отдельным папкам, названия которых, соответствуют уровню сложности языка. Следует удалить подобные записи."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f60859cb",
      "metadata": {
        "id": "f60859cb"
      },
      "outputs": [],
      "source": [
        "# удаление признака `movie`\n",
        "df = df.drop('movie', axis=1)\n",
        "# удаление записей с пропусками\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac76f7bf",
      "metadata": {
        "id": "ac76f7bf"
      },
      "source": [
        "__Проверим наличие полных дубликатов в данных:__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ceae43a",
      "metadata": {
        "id": "2ceae43a",
        "outputId": "b708a7ca-3e7d-4b99-9d62-993a87d9af1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество полных дубликатов: 2\n"
          ]
        }
      ],
      "source": [
        "print(f'Количество полных дубликатов: {df.duplicated().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8c4fd59",
      "metadata": {
        "id": "a8c4fd59"
      },
      "source": [
        "- Надичие дубликарованных строк, связано с наличием одинаковых субтитров в двух изначальных наборах данных, их следует удалить."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28bfd1f7",
      "metadata": {
        "id": "28bfd1f7"
      },
      "outputs": [],
      "source": [
        "# удаление дубликатов\n",
        "df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6156a35",
      "metadata": {
        "id": "b6156a35"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "\n",
        "## Баланс целевого признака\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5b199f9",
      "metadata": {
        "id": "b5b199f9",
        "outputId": "61211767-4d2e-452c-aad4-4157ada91435"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "B2            136\n",
              "B1             52\n",
              "C1             39\n",
              "A2/A2+         25\n",
              "B1, B2          8\n",
              "A2              6\n",
              "A2/A2+, B1      5\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# вывод количества записей по класскам\n",
        "#df['label'] = df['label'].apply(lambda x: str(x))\n",
        "display(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3e067d6",
      "metadata": {
        "id": "f3e067d6"
      },
      "source": [
        "- Как видно из сводной информации, существует дисбаланс класов\n",
        "- Записей по межклассовым (A2/A2+, B1/B2 и тд) не достаточно для обучения классификатора. Небходимо:\n",
        "    - используя [таблицу CEFR/IELS](https://i.postimg.cc/W4YQxZkJ/2023-06-08-15-23-32.png) преобразобать значения в числовой вариант и в последующем решать задачу регрессии\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67b40749",
      "metadata": {
        "id": "67b40749"
      },
      "outputs": [],
      "source": [
        "cefr_dict = {'A2': 3.25, #среднее значение крайних значений [3.0:3.5]\n",
        "             'B1': 4.5,  #среднее значение крайних значений [4.0:5.0]\n",
        "             'B2': 6.0, #среднее значение крайних значений [5.5:6.5]\n",
        "             'C1': 7.5, #среднее значение крайних значений [7.0:8.0]\n",
        "             'A2/A2+': 3.5, #верхняя граница\n",
        "             'A2+': 3.5, #верхняя граница\n",
        "             'B1, B2': 5.25, #среднее значение верхнего B1 и низнего B2 [5.0:5.5]\n",
        "             'A2/A2+, B1': 3.75} #среднее значение верхнего A2 и нижнего B1 [3.5:4.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc53d59",
      "metadata": {
        "id": "7fc53d59"
      },
      "outputs": [],
      "source": [
        "df['ielts_index'] = df['label'].apply(lambda x: cefr_dict[x]).copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "977407eb",
      "metadata": {
        "id": "977407eb"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "\n",
        "## Рассчет коофициентов удобочитаемости Флеша-Кинкейда\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1bcc72",
      "metadata": {
        "id": "4f1bcc72"
      },
      "source": [
        "Тесты на удобочитаемость [Флеша-Кинкейда](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests#Flesch%E2%80%93Kincaid_grade_level) — это тесты на удобочитаемость , предназначенные для определения того, насколько труден для понимания отрывок на английском языке . Есть два теста: Flesch Reading-Ease и Flesch-Kincaid Grade Level. Хотя они используют одни и те же основные меры (длина слова и длина предложения), они имеют разные весовые коэффициенты.\n",
        "\n",
        "- Flesch Reading-Ease:\n",
        "$$\n",
        "FRE = 206.835 - (words/sentences)*1.015 - (syllables/words)*84.6\n",
        "$$\n",
        "\n",
        "- Flesch-Kincaid Grade Level:\n",
        "$$\n",
        "FKGL = (words/sentences)*0.39 + (syllables/words)*11.8 - 15.59\n",
        "$$\n",
        "где:\n",
        "- words - количество слов в тексте;\n",
        "- sentences - количество предложений в тексте;\n",
        "- syllables - количество слогов в тексте"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d63c02d0",
      "metadata": {
        "id": "d63c02d0"
      },
      "outputs": [],
      "source": [
        "# функции для рассчета коофициентов удобочитаемости:\n",
        "def statistics(txt):\n",
        "    total_sentences = len(re.split(r\"[.!?]\", txt))\n",
        "    total_words = len(txt.split(' '))\n",
        "    total_syllables = sum(txt.count(g) for g in 'aeoiu') + txt.count('y')/2\n",
        "    return total_sentences, total_words, total_syllables\n",
        "    \n",
        "def flesch_reading_ease(txt):\n",
        "    sentences, words, syllables = statistics(txt)\n",
        "    fres = 206.835 - (words/sentences)*1.015 - (syllables/words)*84.6\n",
        "    return fres\n",
        "    \n",
        "def flesch_kincaid_grade_level(txt):\n",
        "    sentences, words, syllables = statistics(txt)\n",
        "    fkgl = (words/sentences)*0.39 + (syllables/words)*11.8 - 15.59\n",
        "    return fkgl  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6364b65b",
      "metadata": {
        "id": "6364b65b"
      },
      "outputs": [],
      "source": [
        "df['fres'] = df['subtitles'].apply(flesch_reading_ease)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed1034a6",
      "metadata": {
        "id": "ed1034a6"
      },
      "outputs": [],
      "source": [
        "df['fkgl'] = df['subtitles'].apply(flesch_kincaid_grade_level)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "839f7f66",
      "metadata": {
        "id": "839f7f66"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "\n",
        "## Токенизация и лематизация текста\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8b6e51",
      "metadata": {
        "id": "8b8b6e51"
      },
      "source": [
        "- Перед токенизацией текса, необходимо удалить оставшиеся знаки пунктуации и стоп-слова - список слов, которые не влияют на сложность текста, но могут уменьшить точность модели.\n",
        "- Текенизация - это процесс разделения предложений на слова-компоненты.\n",
        "- Лемматизация и стемминг текста. Обычно тексты содержат разные грамматические формы одного и того же слова, а также могут встречаться однокоренные слова. Лемматизация и стемминг преследуют цель привести все встречающиеся словоформы к одной, нормальной словарной форме."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c723b7",
      "metadata": {
        "id": "95c723b7"
      },
      "outputs": [],
      "source": [
        "# удаление знаков пунктуации\n",
        "df['subtitles'] = df['subtitles'].apply(lambda x: PUNCTUATION.sub('', x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac4da9c5",
      "metadata": {
        "id": "ac4da9c5"
      },
      "source": [
        "___________\n",
        "__stopwords/word_tokenize__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03c1826b",
      "metadata": {
        "id": "03c1826b"
      },
      "outputs": [],
      "source": [
        "# функция для удаления стоп-слов и токенизации текста\n",
        "def stopwords_tokenize(x):\n",
        "    tokens = word_tokenize(x)\n",
        "    tokenization = [word for word in tokens if not word in stopwords.words('english')]\n",
        "    return tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cef06dc2",
      "metadata": {
        "id": "cef06dc2"
      },
      "outputs": [],
      "source": [
        "df['subtitles'] = df['subtitles'].apply(stopwords_tokenize)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6df54b04",
      "metadata": {
        "id": "6df54b04"
      },
      "source": [
        "_________\n",
        "__stemmer/lemmatizer__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb5a1ff4",
      "metadata": {
        "id": "bb5a1ff4"
      },
      "outputs": [],
      "source": [
        "# функция для стеминга и лемматизации\n",
        "def stemmer_lemmatizer(x):\n",
        "    stemmer = [porter_stemmer.stem(s) for s in x]\n",
        "    lemmatizer = [wordnet_lemmatizer.lemmatize(w) for w in stemmer]\n",
        "    return lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3074148b",
      "metadata": {
        "id": "3074148b"
      },
      "outputs": [],
      "source": [
        "df['subtitles'] = df['subtitles'].apply(stemmer_lemmatizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43557284",
      "metadata": {
        "id": "43557284"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "\n",
        "## Рассчет долей слов относительно индекса CEFR\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7fa0cf5",
      "metadata": {
        "id": "d7fa0cf5"
      },
      "source": [
        "- Рассчитаем долю слов в тексте, соответствующих списку слов, разделенные по уровням сложности CEFR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "984267df",
      "metadata": {
        "id": "984267df"
      },
      "outputs": [],
      "source": [
        "# cоздание пустого датафрейма для хранения данных\n",
        "df_info = pd.DataFrame(columns=['a1', 'a2', 'b1', 'b2', 'c1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f3baa0a",
      "metadata": {
        "id": "6f3baa0a"
      },
      "outputs": [],
      "source": [
        "data_info = []\n",
        "# функция рассчета доли слов по уровням сложности\n",
        "def oxford_cefr(x):\n",
        "    a1 = sum(1 for i in x if i in a1_list)\n",
        "    a2 = sum(1 for i in x if i in a2_list)\n",
        "    b1 = sum(1 for i in x if i in b1_list)\n",
        "    b2 = sum(1 for i in x if i in b2_list)\n",
        "    c1 = sum(1 for i in x if i in c1_list)\n",
        "    count_word = a1+a2+b1+b2+c1\n",
        "    a1 = a1/count_word\n",
        "    a2 = a2/count_word\n",
        "    b1 = b1/count_word\n",
        "    b2 = b2/count_word\n",
        "    c1 = c1/count_word\n",
        "    data_info.append({'a1':a1, 'a2':a2, 'b1':b1, 'b2': b2, 'c1':c1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af19b99a",
      "metadata": {
        "id": "af19b99a",
        "outputId": "e2b0fd25-e365-45b5-da83-ec3f3961ad19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "270    None\n",
              "271    None\n",
              "272    None\n",
              "273    None\n",
              "274    None\n",
              "Name: subtitles, Length: 271, dtype: object"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['subtitles'].apply(oxford_cefr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f7bb0cb",
      "metadata": {
        "id": "7f7bb0cb"
      },
      "outputs": [],
      "source": [
        "# объединяем все записи в датасете с помощью функции concat\n",
        "df_info = pd.concat([df_info, pd.DataFrame(data_info)], ignore_index=True)\n",
        "df = pd.concat([df, df_info], axis=1).copy()\n",
        "# удаление записей с пропусками\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c1e94c8",
      "metadata": {
        "id": "1c1e94c8"
      },
      "source": [
        "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
        "\n",
        "\n",
        "- Изучена общая информация.\n",
        "- Обработаны дубликаты и пропуски в данных.\n",
        "- Выявлен дисбаланс классов.\n",
        "- Удалены стоп-слова.\n",
        "- Проведена токенизация и лематизация текста.\n",
        "- Рассчитаны дополнительные признаки:\n",
        "    - Flesch Reading-Ease\n",
        "    - Flesch-Kincaid Grade Level\n",
        "    - Доли слов относительно индекса CEFR\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fda82ecd",
      "metadata": {
        "id": "fda82ecd"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "\n",
        "# Разработка модели ML"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37a34f39",
      "metadata": {
        "id": "37a34f39"
      },
      "source": [
        "- Для обучения моделей машинного обучения по прежнему не хватает записей, но так как субтитры в большенстве своем достаточно длинные, мы в праве разделить их по определенному количеству слов, тем самым увеличив количество записей. При этом рассчитанные ранее статистические данные следует оставить без изменений, тк они были рассчитаны на всем тексте и обладают большей точностью, по сравнению с теми, которые мы можем рассчитать на части данных.\n",
        "   - выберем количество: 100 слов \n",
        "- Некоторые записи могут содержать меньшее число слов, их следует исключить."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e897bba0",
      "metadata": {
        "id": "e897bba0"
      },
      "outputs": [],
      "source": [
        "# определение количества слов в субтитрах\n",
        "df['len'] = df['subtitles'].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b7dfe0",
      "metadata": {
        "id": "81b7dfe0"
      },
      "outputs": [],
      "source": [
        "df = df[df['len']>=100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68be3b0b",
      "metadata": {
        "id": "68be3b0b"
      },
      "outputs": [],
      "source": [
        "# cоздание пустого датафрейма для хранения данных\n",
        "df_div = pd.DataFrame(columns=['subtitles','a1', 'a2', 'b1', 'b2', 'c1', 'fres', 'fkgl','label', 'ielts_index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bdee4f0",
      "metadata": {
        "id": "2bdee4f0"
      },
      "outputs": [],
      "source": [
        "# функция для разделения субтитров\n",
        "len_div = 100 #количество слов в подвыборке, для увеличения наблюдений\n",
        "data = []\n",
        "def text_division(x):\n",
        "    for i in range(len(x['subtitles'])//len_div):\n",
        "        data.append({'subtitles': ' '.join(x['subtitles'][i*len_div:(i+1)*len_div+1]), \n",
        "                     'a1': x['a1'],\n",
        "                     'a2': x['a2'],\n",
        "                     'b1': x['b1'],\n",
        "                     'b2': x['b2'],\n",
        "                     'c1': x['c1'],\n",
        "                     'fres': x['fres'],\n",
        "                     'fkgl': x['fkgl'],\n",
        "                     'label': x['label'],\n",
        "                     'ielts_index': x['ielts_index']})               "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "966efd15",
      "metadata": {
        "id": "966efd15",
        "outputId": "c1e897b2-d002-452e-9ed4-640477c7d384"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "265    None\n",
              "266    None\n",
              "267    None\n",
              "268    None\n",
              "270    None\n",
              "Length: 263, dtype: object"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.apply(text_division, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7caf82fe",
      "metadata": {
        "id": "7caf82fe"
      },
      "outputs": [],
      "source": [
        "# jбъединяем все записи в датасете с помощью функции concat\n",
        "df = pd.concat([df_div, pd.DataFrame(data)], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645745ee",
      "metadata": {
        "id": "645745ee"
      },
      "source": [
        "__Выделение обучающей и тестовой выборок__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac292a44",
      "metadata": {
        "id": "ac292a44",
        "outputId": "05a87079-1c71-4156-f191-3222c885d28b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер выборок: (7826, 8);(1957, 8);(7826, 1);(1957, 1)\n"
          ]
        }
      ],
      "source": [
        "# признаки для обучения\n",
        "X = ['subtitles', 'a1', 'a2', 'b1', 'b2', 'c1', 'fres', 'fkgl']\n",
        "# целевой признак\n",
        "y = ['ielts_index']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[X], df[y], test_size=0.2, random_state=RANDOM_SEED)\n",
        "print(f'Размер выборок: {X_train.shape};{X_test.shape};{y_train.shape};{y_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6144163",
      "metadata": {
        "id": "e6144163"
      },
      "source": [
        "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
        "\n",
        "- Увеличен размер выборки за счет разделения субтитров на несколько записей.\n",
        "- Датафрейм разделен на обучающую и тестовую выборки.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38b08262",
      "metadata": {
        "id": "38b08262"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "\n",
        "## RandomForest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f14dfb5",
      "metadata": {
        "id": "3f14dfb5"
      },
      "source": [
        "- Для обучения модели, необходима векторизация текстовой информации. Поскольку текстовые данные представлены в виде последовательности слов или символов, их необходимо преобразовать в числовой формат, чтобы модель могла работать с ними. Одним из популярных методов векторизации текста является TF-IDF (Term Frequency-Inverse Document Frequency). Этот метод присваивает каждому слову в тексте числовое значение, основанное на его частоте встречаемости в документе (Term Frequency) и обратной частоте встречаемости в корпусе документов (Inverse Document Frequency). Результатом векторизации текста с использованием TF-IDF является числовое представление текста, где каждое слово представлено числовым значением, отражающим его важность в контексте данного текста. Так же необходимо ограничить размерность матрицы, тк в случае сохранения всех параметров, потребуется много времени для реализации данного алгоритма обучения.\n",
        "\n",
        "__TF-IDF векторизация__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "456ad9ea",
      "metadata": {
        "id": "456ad9ea",
        "outputId": "4b42c42a-9303-4489-8abe-4fb2b93fb8a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размерность обучающей матрицы TF-IDF: (7826, 25)\n",
            "Размерность тестовой матрицы TF-IDF: (1957, 25)\n"
          ]
        }
      ],
      "source": [
        "# Векторизация столбца 'subtitles' с помощью TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=25)\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train['subtitles'])\n",
        "X_test_vectorized = vectorizer.transform(X_test['subtitles'])\n",
        "# Вывод размерности матрицы TF-IDF\n",
        "print(\"Размерность обучающей матрицы TF-IDF:\", X_train_vectorized.shape)\n",
        "print(\"Размерность тестовой матрицы TF-IDF:\", X_test_vectorized.shape)\n",
        "\n",
        "# Преобразование векторизованного столбца 'subtitles' в массив NumPy\n",
        "X_train_vectorized = X_train_vectorized.toarray()\n",
        "X_test_vectorized = X_test_vectorized.toarray()\n",
        "\n",
        "# Объединение данных в один набор\n",
        "X_train_combined = np.hstack((X_train_vectorized, X_train.drop('subtitles', axis=1)))\n",
        "X_test_combined = np.hstack((X_test_vectorized, X_test.drop('subtitles', axis=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3b73290",
      "metadata": {
        "id": "b3b73290"
      },
      "source": [
        "__Обучение модели__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a3643e4",
      "metadata": {
        "id": "1a3643e4"
      },
      "outputs": [],
      "source": [
        "# гиперпараметры модели\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 150],\n",
        "    'max_depth': [5, 7],\n",
        "    'min_samples_split': [2, 3]\n",
        "}\n",
        "# параметры модели\n",
        "model_RF = RandomForestRegressor(random_state=RANDOM_SEED)\n",
        "# объект метрики MAE\n",
        "scorer = make_scorer(mean_absolute_error)\n",
        "# параметры RandomizedSearchCV\n",
        "random_search_RF = RandomizedSearchCV(estimator=model_RF,\n",
        "                                      param_distributions=param_grid,\n",
        "                                      n_iter=100,\n",
        "                                      cv=3,\n",
        "                                      verbose=True,\n",
        "                                      random_state=RANDOM_SEED,\n",
        "                                      scoring=scorer,\n",
        "                                      n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d61981e9",
      "metadata": {
        "id": "d61981e9",
        "outputId": "b1ef954e-8da4-4144-b24e-ffba807591e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Оптимальные гиперпараметры:\n",
            "{'n_estimators': 150, 'min_samples_split': 2, 'max_depth': 5}\n",
            "0.5313494403967689\n"
          ]
        }
      ],
      "source": [
        "# обучение модели\n",
        "random_search_RF.fit(X_train_combined, y_train.values.ravel())\n",
        "# сохраним лучшую модель\n",
        "best_model_RF = random_search_RF.best_estimator_\n",
        "# сохраним лучшее значение метрики\n",
        "final_metrics_RF = random_search_RF.best_score_\n",
        "# вывод результатов\n",
        "print(f'Оптимальные гиперпараметры:\\n{random_search_RF.best_params_}\\n{final_metrics_RF}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77507164",
      "metadata": {
        "id": "77507164"
      },
      "source": [
        "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
        "\n",
        "- Оптимальные гитерпараметры для алгоритма RandomForest:\n",
        "    - 'n_estimators': 150\n",
        "    - 'min_samples_split': 2\n",
        "    - 'max_depth': 5\n",
        "    \n",
        "- Метрика качества MAE на обучающих данных при кроссвалидации составляет: 0.53\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73653cf9",
      "metadata": {
        "id": "73653cf9"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "\n",
        "## CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e8957d5",
      "metadata": {
        "id": "5e8957d5"
      },
      "source": [
        "- CatBoost - это градиентный бустинговый алгоритм, разработанный компанией Yandex. Он является мощным инструментом для задач классификации и регрессии, который обладает рядом преимуществ и особенностей.\n",
        "\n",
        "- Одной из основных преимуществ CatBoost является его способность работать напрямую с категориальными признаками, включая текстовые данные. В отличие от многих других алгоритмов, CatBoost может обрабатывать категориальные признаки без необходимости их предварительной векторизации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad6d22a9",
      "metadata": {
        "id": "ad6d22a9"
      },
      "outputs": [],
      "source": [
        "# тестовые признаки \n",
        "text_features = ['subtitles']\n",
        "# pool\n",
        "train_pool = Pool(X_train,\n",
        "                  label=y_train,\n",
        "                  text_features=text_features)\n",
        "\n",
        "test_pool = Pool(X_test,\n",
        "                 text_features=text_features)\n",
        "# целевой признак тестовой выборки\n",
        "y_test_cb = y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd72d1b8",
      "metadata": {
        "id": "fd72d1b8"
      },
      "source": [
        "__optuna-подбор оптимальных гиперпараметров__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a87317f",
      "metadata": {
        "id": "7a87317f",
        "outputId": "8719b2c5-b9f6-4f06-80ea-6795bad47e5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7043, 8), (7043, 1), (1957, 8), (1957, 1), (783, 8), (783, 1))"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# выборки для подбора гиперпараметров CatBoost\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(df[X], df[y], test_size=0.2, random_state=RANDOM_SEED)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=RANDOM_SEED)\n",
        "# размер выборок\n",
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97c40795",
      "metadata": {
        "id": "97c40795"
      },
      "outputs": [],
      "source": [
        "# гиперпараметры optuna\n",
        "def objective(trial):\n",
        "    param = {}\n",
        "    param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
        "    param['depth'] = trial.suggest_int('depth', 9, 15)\n",
        "    param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
        "    param['min_child_samples'] = trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n",
        "    param['grow_policy'] = 'Depthwise'\n",
        "    param['iterations'] = 1000\n",
        "    param['use_best_model'] = True\n",
        "    param['eval_metric'] = 'MAE'\n",
        "    param['od_type'] = 'iter'\n",
        "    param['od_wait'] = 20\n",
        "    param['random_state'] = RANDOM_SEED\n",
        "    param['logging_level'] = 'Silent'\n",
        "    param['text_features'] = text_features\n",
        "    \n",
        "    regressor = CatBoostRegressor(**param)\n",
        "\n",
        "    regressor.fit(X_train.copy(), y_train.copy(),\n",
        "                  eval_set=[(X_test.copy(), y_test.copy())],\n",
        "                  early_stopping_rounds=EARLY_STOPPING_ROUND)\n",
        "    loss = mean_absolute_error(y_valid, regressor.predict(X_valid.copy()))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97efba81",
      "metadata": {
        "scrolled": true,
        "id": "97efba81",
        "outputId": "29cc1509-1c2c-42a6-ce5c-52dbe0a6788b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-03 19:07:55,451] A new study created in memory with name: catboost-seed42\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:13:16,118] Trial 5 finished with value: 0.11235527533125683 and parameters: {'learning_rate': 0.02, 'depth': 10, 'l2_leaf_reg': 4.5, 'min_child_samples': 32}. Best is trial 5 with value: 0.11235527533125683.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:14:24,602] Trial 3 finished with value: 0.131822919967549 and parameters: {'learning_rate': 0.017, 'depth': 9, 'l2_leaf_reg': 2.0, 'min_child_samples': 8}. Best is trial 5 with value: 0.11235527533125683.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:16:17,435] Trial 8 finished with value: 0.12876226564864462 and parameters: {'learning_rate': 0.013000000000000001, 'depth': 10, 'l2_leaf_reg': 4.0, 'min_child_samples': 8}. Best is trial 5 with value: 0.11235527533125683.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:16:45,440] Trial 7 finished with value: 0.09299385221785232 and parameters: {'learning_rate': 0.019000000000000003, 'depth': 13, 'l2_leaf_reg': 3.0, 'min_child_samples': 32}. Best is trial 7 with value: 0.09299385221785232.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:17:46,733] Trial 1 finished with value: 0.09159208023365156 and parameters: {'learning_rate': 0.017, 'depth': 14, 'l2_leaf_reg': 5.5, 'min_child_samples': 32}. Best is trial 1 with value: 0.09159208023365156.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:20:33,467] Trial 0 finished with value: 0.11059168276008682 and parameters: {'learning_rate': 0.014, 'depth': 11, 'l2_leaf_reg': 1.0, 'min_child_samples': 4}. Best is trial 1 with value: 0.09159208023365156.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:21:29,756] Trial 2 finished with value: 0.09038012162176244 and parameters: {'learning_rate': 0.018000000000000002, 'depth': 14, 'l2_leaf_reg': 2.0, 'min_child_samples': 16}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:25:07,549] Trial 4 finished with value: 0.0997017905898607 and parameters: {'learning_rate': 0.02, 'depth': 13, 'l2_leaf_reg': 1.5, 'min_child_samples': 4}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-03 19:26:51,243] Trial 15 finished with value: 0.10743209239881818 and parameters: {'learning_rate': 0.019000000000000003, 'depth': 11, 'l2_leaf_reg': 5.0, 'min_child_samples': 32}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:26:57,911] Trial 6 finished with value: 0.09722524886491622 and parameters: {'learning_rate': 0.014, 'depth': 14, 'l2_leaf_reg': 3.0, 'min_child_samples': 8}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:31:53,567] Trial 14 finished with value: 0.09371475702760247 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 4.0, 'min_child_samples': 16}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:32:58,963] Trial 16 finished with value: 0.09989806019547569 and parameters: {'learning_rate': 0.019000000000000003, 'depth': 12, 'l2_leaf_reg': 1.5, 'min_child_samples': 8}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:33:31,642] Trial 9 finished with value: 0.09836455530121371 and parameters: {'learning_rate': 0.018000000000000002, 'depth': 15, 'l2_leaf_reg': 3.5, 'min_child_samples': 4}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:35:04,214] Trial 10 finished with value: 0.10252028298045607 and parameters: {'learning_rate': 0.017, 'depth': 14, 'l2_leaf_reg': 4.0, 'min_child_samples': 4}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:36:07,576] Trial 17 finished with value: 0.13327704895793493 and parameters: {'learning_rate': 0.012, 'depth': 11, 'l2_leaf_reg': 5.5, 'min_child_samples': 8}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:36:32,856] Trial 18 finished with value: 0.10079822056421966 and parameters: {'learning_rate': 0.014, 'depth': 13, 'l2_leaf_reg': 4.5, 'min_child_samples': 32}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:37:38,200] Trial 13 finished with value: 0.09301645520676272 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 1.5, 'min_child_samples': 8}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-06-03 19:40:25,698] Trial 19 finished with value: 0.11227949550735124 and parameters: {'learning_rate': 0.011, 'depth': 13, 'l2_leaf_reg': 2.5, 'min_child_samples': 16}. Best is trial 2 with value: 0.09038012162176244.\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:3: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['learning_rate'] = trial.suggest_discrete_uniform(\"learning_rate\", 0.01, 0.02, 0.001)\n",
            "/var/folders/1l/cj5j7tnj6q347f0pj242vpfm0000gn/T/ipykernel_3885/3340873305.py:5: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
            "  param['l2_leaf_reg'] = trial.suggest_discrete_uniform('l2_leaf_reg', 1.0, 5.5, 0.5)\n",
            "[I 2023-06-03 19:52:21,895] Trial 22 finished with value: 0.11728346992337901 and parameters: {'learning_rate': 0.01, 'depth': 15, 'l2_leaf_reg': 5.5, 'min_child_samples': 16}. Best is trial 2 with value: 0.09038012162176244.\n",
            "[I 2023-06-03 19:53:47,323] Trial 23 finished with value: 0.10662109775601156 and parameters: {'learning_rate': 0.011, 'depth': 15, 'l2_leaf_reg': 5.5, 'min_child_samples': 16}. Best is trial 2 with value: 0.09038012162176244.\n",
            "[I 2023-06-03 20:07:07,717] Trial 12 finished with value: 0.09070113988838173 and parameters: {'learning_rate': 0.016, 'depth': 14, 'l2_leaf_reg': 3.0, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
            "[I 2023-06-03 20:07:50,135] Trial 11 finished with value: 0.09240136692804589 and parameters: {'learning_rate': 0.012, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
            "[I 2023-06-03 20:16:24,282] Trial 21 finished with value: 0.1063296214759433 and parameters: {'learning_rate': 0.01, 'depth': 15, 'l2_leaf_reg': 5.5, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
            "[I 2023-06-03 20:16:38,527] Trial 20 finished with value: 0.10179649041723511 and parameters: {'learning_rate': 0.011, 'depth': 15, 'l2_leaf_reg': 5.5, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
            "[I 2023-06-03 20:18:37,256] Trial 24 finished with value: 0.09982160262124344 and parameters: {'learning_rate': 0.01, 'depth': 15, 'l2_leaf_reg': 2.0, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
            "[I 2023-06-03 20:20:07,934] Trial 26 finished with value: 0.10050195377238245 and parameters: {'learning_rate': 0.01, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 1}. Best is trial 2 with value: 0.09038012162176244.\n",
            "[I 2023-06-03 20:22:06,336] Trial 25 finished with value: 0.08805955872892557 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 2.5, 'min_child_samples': 1}. Best is trial 25 with value: 0.08805955872892557.\n",
            "[I 2023-06-03 20:22:39,486] Trial 27 finished with value: 0.09063355848597779 and parameters: {'learning_rate': 0.016, 'depth': 15, 'l2_leaf_reg': 5.5, 'min_child_samples': 1}. Best is trial 25 with value: 0.08805955872892557.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 11h 54min 56s, sys: 7min 26s, total: 12h 2min 23s\n",
            "Wall time: 1h 14min 44s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "study = optuna.create_study(study_name=f'catboost-seed{RANDOM_SEED}')\n",
        "study.optimize(objective, n_trials=1000, n_jobs=-1, timeout=2400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fbea7a9",
      "metadata": {
        "id": "9fbea7a9",
        "outputId": "6d15a98a-3777-4698-eb3d-674077cb2fec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.08805955872892557"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# лучшая метрика\n",
        "study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94d2092",
      "metadata": {
        "id": "a94d2092",
        "outputId": "d7d9d518-6284-4990-ccc6-4fa82c90de34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'learning_rate': 0.016,\n",
              " 'depth': 15,\n",
              " 'l2_leaf_reg': 2.5,\n",
              " 'min_child_samples': 1}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# оптимальные гиперпараметры\n",
        "study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d8b6fe",
      "metadata": {
        "id": "45d8b6fe"
      },
      "source": [
        "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
        "\n",
        "- Оптимальные гитерпараметры для алгоритма CatBoost, при использовании алгоритма optuna:\n",
        "    - 'learning_rate': 0.016\n",
        "    - 'depth': 15\n",
        "    - 'l2_leaf_reg': 2.5\n",
        "    - 'min_child_samples': 1\n",
        "    \n",
        "- Метрика качества MAE на обучающих данных при кроссвалидации составляет: 0.09\n",
        "    ____________\n",
        "    \n",
        "- Для дальнейшего обучения выбираем алгоритм CatBoost, показывающий лучшую метрику качества. Однако, часть параметров не будет использоваться далее, что увеличит скорость обучения и предсказаний. В дальнейшем, при необходимости более точных данных, можно их можно будет использовать в модели.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e95803",
      "metadata": {
        "id": "22e95803"
      },
      "source": [
        "__Обучение модели__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b8bbd78",
      "metadata": {
        "id": "3b8bbd78"
      },
      "outputs": [],
      "source": [
        "# гиперпараметры модели\n",
        "parameters = {'verbose': 100,\n",
        "              'text_features': ['subtitles'],\n",
        "              'eval_metric': 'MAE',\n",
        "              'iterations': 1000,\n",
        "              'learning_rate': 0.2,\n",
        "              'random_seed':RANDOM_SEED,\n",
        "              'early_stopping_rounds': 30\n",
        "             }\n",
        "# параметры модели\n",
        "regressor = CatBoostRegressor(**parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8272587a",
      "metadata": {
        "id": "8272587a",
        "outputId": "edf6d832-3bfb-4976-a844-57f2957ea26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.9101034\ttotal: 95.9ms\tremaining: 1m 35s\n",
            "100:\tlearn: 0.1426646\ttotal: 3.78s\tremaining: 33.7s\n",
            "200:\tlearn: 0.0779433\ttotal: 7.45s\tremaining: 29.6s\n",
            "300:\tlearn: 0.0562830\ttotal: 11.2s\tremaining: 26.1s\n",
            "400:\tlearn: 0.0441051\ttotal: 15s\tremaining: 22.3s\n",
            "500:\tlearn: 0.0359515\ttotal: 18.6s\tremaining: 18.5s\n",
            "600:\tlearn: 0.0305177\ttotal: 22.3s\tremaining: 14.8s\n",
            "700:\tlearn: 0.0263480\ttotal: 26s\tremaining: 11.1s\n",
            "800:\tlearn: 0.0228443\ttotal: 29.7s\tremaining: 7.37s\n",
            "900:\tlearn: 0.0200240\ttotal: 33.4s\tremaining: 3.67s\n",
            "999:\tlearn: 0.0177868\ttotal: 37s\tremaining: 0us\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x2972b65c0>"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# обучение модели\n",
        "regressor.fit(train_pool)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d439a000",
      "metadata": {
        "id": "d439a000"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "\n",
        "## Проверка модели на тестовой выборке"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d156ab5b",
      "metadata": {
        "id": "d156ab5b",
        "outputId": "c19365bb-3e0b-40ce-c3e6-b9f9bd432a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Средняя абсолютная ошибка (MAE): 0.05040942850434126\n"
          ]
        }
      ],
      "source": [
        "# предказание данных\n",
        "predict = regressor.predict(test_pool)\n",
        "mae = mean_absolute_error(y_test_cb, predict)\n",
        "# вывод результатов\n",
        "print(\"Средняя абсолютная ошибка (MAE):\", mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a526795",
      "metadata": {
        "id": "6a526795"
      },
      "source": [
        "_________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "382647ff",
      "metadata": {
        "id": "382647ff"
      },
      "outputs": [],
      "source": [
        "# сохранение итоговой модели\n",
        "regressor.save_model('catboost_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aa8f327",
      "metadata": {
        "id": "4aa8f327"
      },
      "source": [
        "<div style=\"padding:0px 20px 10px; \n",
        "            color:#004346;\n",
        "            font-size:15px;\n",
        "            display:fill;\n",
        "            text-align:center;\n",
        "            border-radius:20px;\n",
        "            border: 5px double;\n",
        "            border-color:#201E20;\n",
        "            background-color: #E8F1F2;\n",
        "            overflow:hidden;\n",
        "            font-weight:400\"> \n",
        "\n",
        "\n",
        "# Вывод"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abde2eb9",
      "metadata": {
        "id": "abde2eb9"
      },
      "source": [
        "- В ходе проведения исследования была выполнена предобработка данных, включающая очистку и лемматизацию текстовых признаков. Для векторизации текста был применен метод TF-IDF, который позволяет представить тексты в виде числовых признаков, учитывающих важность каждого термина в документе.\n",
        "\n",
        "- Для настройки гиперпараметров модели CatBoost был использован фреймворк Optuna. Optuna провел исследование пространства гиперпараметров, оценивая производительность модели с различными комбинациями параметров. Целевая метрика, в данном случае MAE, была определена для оптимизации. В результате подбора гиперпараметров были получены оптимальные значения, которые позволяют достичь наилучшей производительности модели CatBoost на данной задаче и составиляют 0.05 на тестовой выборке.\n",
        "\n",
        "- Полученная модель будет использоваться в разработке сервиса, предназначенного для определения уровня сложности английского языка в фильмах. Этот сервис будет доступен через платформу Streamlit, что позволит пользователям оценивать и анализировать сложность субтитров и основываться на предсказанных значениях индекса IELTS или CEFR"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}